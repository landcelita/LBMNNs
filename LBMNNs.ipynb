{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg2kWbrMsFfB0QR5ERrLRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/landcelita/LBMNNs/blob/master/LBMNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iltDTo-5uQCo",
        "outputId": "67a73b06-a924-4dc2-cbfd-4fcd82c2a2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygrib\n",
            "  Downloading pygrib-2.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 4.0 MB/s \n",
            "\u001b[?25hCollecting pyproj\n",
            "  Downloading pyproj-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 82.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pygrib) (1.21.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from pyproj->pygrib) (2022.12.7)\n",
            "Installing collected packages: pyproj, pygrib\n",
            "Successfully installed pygrib-2.1.4 pyproj-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz9u0saErhps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import time\n",
        "import datetime as dt\n",
        "import pygrib\n",
        "from datetime import timedelta\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.multiprocessing as multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHaRtnCTrsIb",
        "outputId": "d0d78b72-43ba-4235-874a-689003f640c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InputLayer(nn.Module):\n",
        "    def __init__(self, height, width):\n",
        "        super().__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "    def forward(self, u_vert, u_hori, rho):\n",
        "        # use feq as input field\n",
        "        # todo: make this layer be also learnable\n",
        "        \n",
        "        # feq(x,v) = C[v] * rho * (1 + 3 v.u + 4.5 (v.u)^2 - 1.5 u^2)\n",
        "        feq = torch.empty((3, 3, self.height, self.width), dtype=torch.float32, device=device)\n",
        "        C = torch.tensor([[1.0/36.0, 1.0/9.0, 1.0/36.0], [1.0/9.0, 4.0/9.0, 1.0/9.0], [1.0/36.0, 1.0/9.0, 1.0/36.0]], dtype=torch.float32, device=device)\n",
        "        u_squared = u_vert ** 2 + u_hori ** 2\n",
        "        \n",
        "        for dr in range(-1, 2):\n",
        "            for dc in range(-1, 2):\n",
        "                v_dot_u = dr * u_vert + dc * u_hori\n",
        "                feq[dr+1, dc+1, :, :] = C[dr+1,dc+1] * rho * (1.0 + 3.0 * v_dot_u + 4.5 * v_dot_u * v_dot_u - 1.5 * u_squared)\n",
        "                \n",
        "        return feq"
      ],
      "metadata": {
        "id": "cuOiERZ-r6oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for InputLayer\n",
        "# # Later, I'll check the immutability of the InputLayer\n",
        "#  - it must put out the same tensor even after the weights are updated\n",
        "def test_for_InputLayer():\n",
        "    input_layer_u_vert = torch.tensor([[0.1]], dtype=torch.float32, device=device)\n",
        "    input_layer_u_hori = torch.tensor([[-0.3]], dtype=torch.float32, device=device)\n",
        "    input_layer_rho = torch.tensor([[0.8]], dtype=torch.float32, device=device)\n",
        "\n",
        "    input_layer = InputLayer(1, 1).to(device)\n",
        "    feq = input_layer(input_layer_u_vert, input_layer_u_hori, input_layer_rho)\n",
        "    print(torch.sum(feq[2,:,0,0] - feq[0,:,0,0]) / torch.sum(feq[:,:,0,0])) # u_vert\n",
        "    print(torch.sum(feq[:,2,0,0] - feq[:,0,0,0]) / torch.sum(feq[:,:,0,0])) # u_hori\n",
        "    print(torch.sum(feq[:,:,0,0])) # rho\n",
        "\n",
        "test_for_InputLayer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cymZiWDGr8bd",
        "outputId": "71286776-af0a-4811-e964-9b92962b5a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1000, device='cuda:0')\n",
            "tensor(-0.3000, device='cuda:0')\n",
            "tensor(0.8000, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StreamingLayer(nn.Module):\n",
        "    def __init__(self, in_height, in_width):\n",
        "        super().__init__()\n",
        "        self.in_height = in_height\n",
        "        self.in_width = in_width\n",
        "        \n",
        "        self.w0 = nn.Parameter(torch.zeros((in_height-2, in_width-2), dtype=torch.float32, device=device))\n",
        "        self.w1 = nn.Parameter(torch.ones((in_height-2, in_width-2), dtype=torch.float32, device=device))\n",
        "        \n",
        "    def forward(self, f_prev):\n",
        "        # f(x,v) = w0(x,v) + w1(x,v) * f_prev(x-v,v)\n",
        "        \n",
        "        f = torch.empty((3, 3, self.in_height-2, self.in_width-2), dtype=torch.float32, device=device)\n",
        "        for dr in range(-1, 2):\n",
        "            for dc in range(-1, 2):\n",
        "                f[dr+1,dc+1,:,:] = self.w0 + self.w1 * f_prev[dr+1,dc+1,1-dr:self.in_height-1-dr,1-dc:self.in_width-1-dc]\n",
        "        \n",
        "        return f\n",
        "                "
      ],
      "metadata": {
        "id": "j_xf25cwsBy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for StreamingLayer\n",
        "def test_for_StreamingLayer():\n",
        "    input_f_prev = torch.zeros((3, 3, 3, 3), dtype=torch.float64, device=device)\n",
        "    input_f_prev[2,2,0,0] = 1.0\n",
        "    input_f_prev[2,1,0,1] = 2.0\n",
        "    input_f_prev[2,0,0,2] = 3.0\n",
        "    input_f_prev[1,2,1,0] = 4.0\n",
        "    input_f_prev[1,1,1,1] = 5.0\n",
        "    input_f_prev[1,0,1,2] = 6.0\n",
        "    input_f_prev[0,2,2,0] = 7.0\n",
        "    input_f_prev[0,1,2,1] = 8.0\n",
        "    input_f_prev[0,0,2,2] = 9.0\n",
        "    print(input_f_prev)\n",
        "\n",
        "    streaming_layer = StreamingLayer(3, 3).to(device)\n",
        "    f_streamed = streaming_layer(input_f_prev)\n",
        "    print(f_streamed)\n",
        "\n",
        "test_for_StreamingLayer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw9Mo_MOsFCP",
        "outputId": "200fdb3f-94ca-447e-ad12-c2f7dc467ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 9.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 8., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [7., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 6.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 5., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [4., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 3.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[0., 2., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[1., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]]], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[[[9.]],\n",
            "\n",
            "         [[8.]],\n",
            "\n",
            "         [[7.]]],\n",
            "\n",
            "\n",
            "        [[[6.]],\n",
            "\n",
            "         [[5.]],\n",
            "\n",
            "         [[4.]]],\n",
            "\n",
            "\n",
            "        [[[3.]],\n",
            "\n",
            "         [[2.]],\n",
            "\n",
            "         [[1.]]]], device='cuda:0', grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CollidingLayer(nn.Module):\n",
        "    def __init__(self, in_height, in_width):\n",
        "        super().__init__()\n",
        "        self.in_height = in_height\n",
        "        self.in_width = in_width\n",
        "        \n",
        "        self.w1 = nn.Parameter(torch.full((in_height, in_width), fill_value=3.0, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        self.w2 = nn.Parameter(torch.full((in_height, in_width), fill_value=0.0, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        self.w3 = nn.Parameter(torch.full((in_height, in_width), fill_value=4.5, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        self.w4 = nn.Parameter(torch.full((in_height, in_width), fill_value=-1.5, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        \n",
        "    def forward(self, f_prev):\n",
        "        # feq(x,v) = C(v) * rho(x) * (1 + w1(x,v) v.u(x) + w2(x,v) vXu(x) + w3(x,v) (v.u(x))^2 + w4(x,v) u(x)^2)\n",
        "        # f = (f_prev + feq) / 2\n",
        "        C = torch.tensor([[1.0/36.0, 1.0/9.0, 1.0/36.0], [1.0/9.0, 4.0/9.0, 1.0/9.0], [1.0/36.0, 1.0/9.0, 1.0/36.0]], dtype=torch.float32, device=device)\n",
        "        \n",
        "        rho = torch.sum(f_prev, dim=(0,1))\n",
        "        u_vert = (f_prev[2,0,:,:] + f_prev[2,1,:,:] + f_prev[2,2,:,:] - f_prev[0,0,:,:] - f_prev[0,1,:,:] - f_prev[0,2,:,:]) / rho\n",
        "        u_hori = (f_prev[0,2,:,:] + f_prev[1,2,:,:] + f_prev[2,2,:,:] - f_prev[0,0,:,:] - f_prev[1,0,:,:] - f_prev[2,0,:,:]) / rho\n",
        "        u_squared = u_vert ** 2 + u_hori ** 2\n",
        "        feq = torch.empty((3, 3, self.in_height, self.in_width), dtype=torch.float32, device=device)\n",
        "        \n",
        "        for dr in range(-1, 2):\n",
        "            for dc in range(-1, 2):\n",
        "                v_dot_u = dr * u_vert + dc * u_hori\n",
        "                vXu = dr * u_hori - dc * u_vert\n",
        "                feq[dr+1, dc+1, :, :] = C[dr+1,dc+1] * rho * (1.0 + (self.w1 + self.w3 * v_dot_u) * v_dot_u + self.w2 * vXu + self.w4 * u_squared)\n",
        "        \n",
        "        return (f_prev + feq) / 2.0"
      ],
      "metadata": {
        "id": "p1qYEjs3sH_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for CollidingLayer\n",
        "def test_for_CollidingLayer():\n",
        "    input_f = torch.tensor([[[[9., 9.]],[[8., 8.]],[[7., 7.]]],[[[6., 6.]],[[5., 5.]],[[4., 4.]]],[[[3., 3.]],[[2., 2.]],[[1., 1.]]]], dtype=torch.float32, device=device)\n",
        "    colliding_layer = CollidingLayer(1, 2)\n",
        "    collided_field = colliding_layer(input_f)\n",
        "\n",
        "    print(torch.sum(collided_field[:,:,0,0])) # rho 45.0\n",
        "    print((torch.sum(collided_field[2,:,0,0]) - torch.sum(collided_field[0,:,0,0])) / torch.sum(collided_field[:,:,0,0])) # u_vert\n",
        "    print((1.+2.+3.-9.-8.-7.)/45.)\n",
        "    print((torch.sum(collided_field[:,2,0,0]) - torch.sum(collided_field[:,0,0,0])) / torch.sum(collided_field[:,:,0,0])) # u_hori\n",
        "    print((1.+4.+7.-3.-6.-9.)/45.)\n",
        "\n",
        "test_for_CollidingLayer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAzNVUB0sMSw",
        "outputId": "8be4a7ad-09e5-4220-8f1d-551c253b6c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(45., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "tensor(-0.4000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "-0.4\n",
            "tensor(-0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "-0.13333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputLayer(nn.Module):\n",
        "    def __init__(self, height, width):\n",
        "        super().__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "    def forward(self, f):\n",
        "        rho = torch.sum(f, dim=(0,1))\n",
        "        u_vert = (f[2,0,:,:] + f[2,1,:,:] + f[2,2,:,:] - f[0,0,:,:] - f[0,1,:,:] - f[0,2,:,:]) / rho\n",
        "        u_hori = (f[0,2,:,:] + f[1,2,:,:] + f[2,2,:,:] - f[0,0,:,:] - f[1,0,:,:] - f[2,0,:,:]) / rho\n",
        "        return u_vert, u_hori"
      ],
      "metadata": {
        "id": "OD2zGC-usOZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LBM(nn.Module):\n",
        "    margin = 4\n",
        "    \n",
        "    def __init__(self, height, width):\n",
        "        super(LBM, self).__init__()\n",
        "        self.input_layer = InputLayer(height, width)\n",
        "        self.streaming1_layer = StreamingLayer(height, width)\n",
        "        self.colliding1_layer = CollidingLayer(height-2, width-2)\n",
        "        self.streaming2_layer = StreamingLayer(height-2, width-2)\n",
        "        self.colliding2_layer = CollidingLayer(height-4, width-4)\n",
        "        self.streaming3_layer = StreamingLayer(height-4, width-4)\n",
        "        self.colliding3_layer = CollidingLayer(height-6, width-6)\n",
        "        self.streaming4_layer = StreamingLayer(height-6, width-6)\n",
        "        self.output_layer = OutputLayer(height-8, width-8)\n",
        "        \n",
        "    def forward(self, u_vert, u_hori, rho):\n",
        "        f = self.input_layer(u_vert, u_hori, rho)\n",
        "        f = self.streaming1_layer(f)\n",
        "        f = self.colliding1_layer(f)\n",
        "        f = self.streaming2_layer(f)\n",
        "        f = self.colliding2_layer(f)\n",
        "        f = self.streaming3_layer(f)\n",
        "        f = self.colliding3_layer(f)\n",
        "        f = self.streaming4_layer(f)\n",
        "        u_vert_out, u_hori_out = self.output_layer(f)\n",
        "        return u_vert_out, u_hori_out"
      ],
      "metadata": {
        "id": "uJllOre8sQ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(u_vert_pred, u_hori_pred, u_vert_target, u_hori_target):\n",
        "    # MSE\n",
        "    return torch.sum(torch.square(u_vert_pred - u_vert_target) + torch.square(u_hori_pred - u_hori_target)) * 10000."
      ],
      "metadata": {
        "id": "C4tT4O7lsTiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherDatasetLazy(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_dir, datetimes, transform, target_transform, margin):\n",
        "        self.src_dir = src_dir\n",
        "        self.input_paths = []\n",
        "        self.target_paths = []\n",
        "        self.margin = margin # this value is the number of streaming layers that reduce the border cells.\n",
        "        # eg. ...                            xxx\n",
        "        #     ...  --(1 Streaming Layer)-->  x.x\n",
        "        #     ...                            xxx\n",
        "        for datetime in datetimes:\n",
        "            self.input_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "            datetime += timedelta(hours=3)\n",
        "            self.target_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        input_grib = pygrib.open(self.input_paths[idx])\n",
        "        rho = torch.from_numpy(np.array(input_grib.select()[0].values, dtype=np.float32)).to(device)\n",
        "        u_hori = torch.from_numpy(np.array(input_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "        u_vert = torch.from_numpy(np.array(input_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "        target_grib = pygrib.open(self.target_paths[idx])\n",
        "        u_hori_target = torch.from_numpy(np.array(target_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "        u_vert_target = torch.from_numpy(np.array(target_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "        u_vert, u_hori, rho = self.transform(u_vert, u_hori, rho)\n",
        "        u_vert_target, u_hori_target = self.target_transform(u_vert_target, u_hori_target, self.margin)\n",
        "        return {\n",
        "            \"u_vert\": u_vert,\n",
        "            \"u_hori\": u_hori,\n",
        "            \"rho\": rho,\n",
        "            \"u_vert_target\": u_vert_target,\n",
        "            \"u_hori_target\": u_hori_target\n",
        "        }"
      ],
      "metadata": {
        "id": "6te31vRosV-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_dir, datetimes, transform, target_transform, margin):\n",
        "        self.src_dir = src_dir\n",
        "        self.input_paths = []\n",
        "        self.target_paths = []\n",
        "        self.margin = margin # this value is the number of streaming layers that reduce the border cells.\n",
        "        # eg. ...                            xxx\n",
        "        #     ...  --(1 Streaming Layer)-->  x.x\n",
        "        #     ...                            xxx\n",
        "        for datetime in datetimes:\n",
        "            self.input_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "            datetime += timedelta(hours=3)\n",
        "            self.target_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "        self.rhos = []\n",
        "        self.u_horis = []\n",
        "        self.u_verts = []\n",
        "        self.u_hori_targets = []\n",
        "        self.u_vert_targets = []\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        now = time.time()\n",
        "        for idx in range(len(self.input_paths)):\n",
        "            if (idx+1) % 100 == 0:\n",
        "                print(f'{idx+1} samples collected, {time.time() - now:.2f} s')\n",
        "                now = time.time()\n",
        "            input_grib = pygrib.open(self.input_paths[idx])\n",
        "            rho = torch.from_numpy(np.array(input_grib.select()[0].values, dtype=np.float32)).to(device)\n",
        "            u_hori = torch.from_numpy(np.array(input_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "            u_vert = torch.from_numpy(np.array(input_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "            target_grib = pygrib.open(self.target_paths[idx])\n",
        "            u_hori_target = torch.from_numpy(np.array(target_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "            u_vert_target = torch.from_numpy(np.array(target_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "            self.rhos.append(rho)\n",
        "            self.u_horis.append(u_hori)\n",
        "            self.u_verts.append(u_vert)\n",
        "            self.u_hori_targets.append(u_hori_target)\n",
        "            self.u_vert_targets.append(u_vert_target)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        u_vert, u_hori, rho = self.transform(self.u_verts[idx], self.u_horis[idx], self.rhos[idx])\n",
        "        u_vert_target, u_hori_target = self.target_transform(self.u_vert_targets[idx], self.u_hori_targets[idx], self.margin)\n",
        "        return {\n",
        "            \"u_vert\": u_vert,\n",
        "            \"u_hori\": u_hori,\n",
        "            \"rho\": rho,\n",
        "            \"u_vert_target\": u_vert_target,\n",
        "            \"u_hori_target\": u_hori_target\n",
        "        }"
      ],
      "metadata": {
        "id": "nhjZS9lW8Ml9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(u_vert, u_hori, rho):\n",
        "    # 下向き正\n",
        "    return u_vert * -0.01, u_hori * 0.01, rho * 0.0001\n",
        "\n",
        "def target_transform(u_vert, u_hori, margin):\n",
        "    if margin == 0:\n",
        "        return u_vert * -0.01, u_hori * 0.01\n",
        "    else:\n",
        "        return u_vert[margin:-margin, margin:-margin] * -0.01, u_hori[margin:-margin, margin:-margin] * 0.01"
      ],
      "metadata": {
        "id": "R4PkTjNMscJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for WeatherDataset\n",
        "def test_for_weatherdataset():\n",
        "    datetimeset = [dt.datetime(2011, 7, 1), dt.datetime(2011, 7, 2)]\n",
        "    grib = pygrib.open('/content/drive/MyDrive/lab_data/data/2011070103.grib2')\n",
        "    u_vert = np.array(grib.select()[2].values, dtype=np.float32)\n",
        "    src_dir = '/content/drive/MyDrive/lab_data/data/'\n",
        "    weather_dataset = WeatherDataset(src_dir, datetimeset, transform, target_transform, 1)\n",
        "    u_vert_direct = torch.from_numpy(u_vert).to(device)\n",
        "    u_vert_target = weather_dataset.__getitem__(0)['u_vert_target']\n",
        "    print(weather_dataset.__len__()) # 2\n",
        "    print(torch.equal(u_vert_target, u_vert_direct[1:-1, 1:-1] * -0.01)) # True\n",
        "    print(u_vert_direct.size())\n",
        "\n",
        "test_for_weatherdataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0TlxIcKsev_",
        "outputId": "b566e8a2-b570-4546-e2dd-6471ea35a7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "True\n",
            "torch.Size([505, 481])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset_and_dataloader():\n",
        "    print('Creating a dataset and dataloader...')\n",
        "    data_dir = '/content/drive/MyDrive/lab_data/data'\n",
        "    datetimeset = [dt.datetime(2011+i, 7, 1, 0) + timedelta(days=j) for i in range(10) for j in range(92)]\n",
        "    dataset = WeatherDataset(data_dir, datetimeset, transform, target_transform, LBM.margin)\n",
        "    batch_size = 1\n",
        "    train_split = 0.8\n",
        "    shuffle_dataset = True # if false, this model will learn only by the 'past' data, and forcast the 'future' data.\n",
        "    random_seed = 42\n",
        "    \n",
        "    dataset_size =  len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(train_split * dataset_size))\n",
        "    if shuffle_dataset:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, valid_indices = indices[:split], indices[split:]\n",
        "    \n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "    \n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=0)\n",
        "    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=0)\n",
        "\n",
        "    return dataset, train_loader, valid_loader\n",
        "\n",
        "dataset, train_loader, valid_loader = make_dataset_and_dataloader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEypdBd3EN28",
        "outputId": "f0991c6d-ebdf-4756-eb96-defc13f0c036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a dataset and dataloader...\n",
            "100 samples collected, 61.20 s\n",
            "200 samples collected, 64.40 s\n",
            "300 samples collected, 62.14 s\n",
            "400 samples collected, 63.71 s\n",
            "500 samples collected, 63.46 s\n",
            "600 samples collected, 64.39 s\n",
            "700 samples collected, 64.82 s\n",
            "800 samples collected, 66.43 s\n",
            "900 samples collected, 64.26 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# todo: enable the model to receive batch data\n",
        "def main(dataset, train_loader, valid_loader):\n",
        "    print('Creating the model...')\n",
        "    lbm = LBM(505, 481).to(device) # got by the prev cell\n",
        "    \n",
        "    num_epochs = 200\n",
        "    total_time = 0.0\n",
        "    \n",
        "    optimizer = torch.optim.Adam(lbm.parameters())\n",
        "    \n",
        "    print(\"optimizer = \" + str(optimizer))\n",
        "    print(\"max_epochs = %3d \" % num_epochs)\n",
        "    \n",
        "    print('Training the model...')\n",
        "    lbm.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_started_time = time.time()\n",
        "        for (batch_idx, batch) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            u_vert_out, u_hori_out = lbm(batch['u_vert'].squeeze(), batch['u_hori'].squeeze(), batch['rho'].squeeze())\n",
        "            loss_val = loss_func(u_vert_out, u_hori_out, batch['u_vert_target'].squeeze(), batch['u_hori_target'].squeeze())\n",
        "            epoch_loss += loss_val.item()\n",
        "            loss_val.backward()\n",
        "            # if batch_idx % 100 == 0:\n",
        "            #     print(f'batch: {batch_idx}')\n",
        "            optimizer.step()\n",
        "        \n",
        "        print(\"epoch = %4d  loss = %.4e  epoch time = %0.2fs\" % (epoch, epoch_loss, time.time() - epoch_started_time))\n",
        "    print('Done')\n",
        "    \n",
        "    print('Computing the model accuracy')\n",
        "    lbm.eval()\n",
        "        \n",
        "main(dataset, train_loader, valid_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rQXqhgwqsitM",
        "outputId": "1e3e134f-b016-4572-a087-441673ec4e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the model...\n",
            "optimizer = Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "max_epochs = 200 \n",
            "Training the model...\n",
            "epoch =    0  loss = 8.3180e+08  epoch time = 25.95s\n",
            "epoch =    1  loss = 8.1860e+08  epoch time = 25.71s\n",
            "epoch =    2  loss = 8.1479e+08  epoch time = 25.77s\n",
            "epoch =    3  loss = 8.1186e+08  epoch time = 25.68s\n",
            "epoch =    4  loss = 8.0944e+08  epoch time = 25.71s\n",
            "epoch =    5  loss = 8.0780e+08  epoch time = 25.74s\n",
            "epoch =    6  loss = 8.0679e+08  epoch time = 25.72s\n",
            "epoch =    7  loss = 8.0555e+08  epoch time = 25.96s\n",
            "epoch =    8  loss = 8.0463e+08  epoch time = 25.98s\n",
            "epoch =    9  loss = 8.0372e+08  epoch time = 26.07s\n",
            "epoch =   10  loss = 8.0330e+08  epoch time = 25.62s\n",
            "epoch =   11  loss = 8.0250e+08  epoch time = 26.05s\n",
            "epoch =   12  loss = 8.0197e+08  epoch time = 25.77s\n",
            "epoch =   13  loss = 8.0143e+08  epoch time = 25.71s\n",
            "epoch =   14  loss = 8.0099e+08  epoch time = 25.74s\n",
            "epoch =   15  loss = 8.0062e+08  epoch time = 25.77s\n",
            "epoch =   16  loss = 8.0003e+08  epoch time = 25.80s\n",
            "epoch =   17  loss = 7.9976e+08  epoch time = 26.03s\n",
            "epoch =   18  loss = 7.9941e+08  epoch time = 26.18s\n",
            "epoch =   19  loss = 7.9922e+08  epoch time = 26.06s\n",
            "epoch =   20  loss = 7.9879e+08  epoch time = 25.73s\n",
            "epoch =   21  loss = 7.9849e+08  epoch time = 26.12s\n",
            "epoch =   22  loss = 7.9830e+08  epoch time = 25.93s\n",
            "epoch =   23  loss = 7.9794e+08  epoch time = 25.73s\n",
            "epoch =   24  loss = 7.9764e+08  epoch time = 25.71s\n",
            "epoch =   25  loss = 7.9749e+08  epoch time = 25.83s\n",
            "epoch =   26  loss = 7.9702e+08  epoch time = 25.79s\n",
            "epoch =   27  loss = 7.9689e+08  epoch time = 26.01s\n",
            "epoch =   28  loss = 7.9668e+08  epoch time = 25.66s\n",
            "epoch =   29  loss = 7.9650e+08  epoch time = 26.08s\n",
            "epoch =   30  loss = 7.9624e+08  epoch time = 25.90s\n",
            "epoch =   31  loss = 7.9597e+08  epoch time = 25.96s\n",
            "epoch =   32  loss = 7.9571e+08  epoch time = 25.65s\n",
            "epoch =   33  loss = 7.9556e+08  epoch time = 25.75s\n",
            "epoch =   34  loss = 7.9543e+08  epoch time = 25.70s\n",
            "epoch =   35  loss = 7.9507e+08  epoch time = 25.68s\n",
            "epoch =   36  loss = 7.9490e+08  epoch time = 25.69s\n",
            "epoch =   37  loss = 7.9462e+08  epoch time = 25.70s\n",
            "epoch =   38  loss = 7.9454e+08  epoch time = 25.66s\n",
            "epoch =   39  loss = 7.9432e+08  epoch time = 26.18s\n",
            "epoch =   40  loss = 7.9415e+08  epoch time = 26.30s\n",
            "epoch =   41  loss = 7.9396e+08  epoch time = 25.86s\n",
            "epoch =   42  loss = 7.9371e+08  epoch time = 25.70s\n",
            "epoch =   43  loss = 7.9373e+08  epoch time = 25.72s\n",
            "epoch =   44  loss = 7.9339e+08  epoch time = 25.69s\n",
            "epoch =   45  loss = 7.9329e+08  epoch time = 25.77s\n",
            "epoch =   46  loss = 7.9310e+08  epoch time = 25.75s\n",
            "epoch =   47  loss = 7.9289e+08  epoch time = 25.71s\n",
            "epoch =   48  loss = 7.9271e+08  epoch time = 25.78s\n",
            "epoch =   49  loss = 7.9252e+08  epoch time = 25.96s\n",
            "epoch =   50  loss = 7.9251e+08  epoch time = 26.13s\n",
            "epoch =   51  loss = 7.9232e+08  epoch time = 26.04s\n",
            "epoch =   52  loss = 7.9207e+08  epoch time = 25.59s\n",
            "epoch =   53  loss = 7.9195e+08  epoch time = 25.73s\n",
            "epoch =   54  loss = 7.9158e+08  epoch time = 25.74s\n",
            "epoch =   55  loss = 7.9168e+08  epoch time = 25.73s\n",
            "epoch =   56  loss = 7.9151e+08  epoch time = 25.74s\n",
            "epoch =   57  loss = 7.9138e+08  epoch time = 25.74s\n",
            "epoch =   58  loss = 7.9109e+08  epoch time = 25.73s\n",
            "epoch =   59  loss = 7.9108e+08  epoch time = 25.98s\n",
            "epoch =   60  loss = 7.9077e+08  epoch time = 26.06s\n",
            "epoch =   61  loss = 7.9078e+08  epoch time = 26.13s\n",
            "epoch =   62  loss = 7.9033e+08  epoch time = 25.74s\n",
            "epoch =   63  loss = 7.9053e+08  epoch time = 25.65s\n",
            "epoch =   64  loss = 7.9035e+08  epoch time = 25.90s\n",
            "epoch =   65  loss = 7.9024e+08  epoch time = 25.93s\n",
            "epoch =   66  loss = 7.8993e+08  epoch time = 25.76s\n",
            "epoch =   67  loss = 7.8989e+08  epoch time = 26.14s\n",
            "epoch =   68  loss = 7.8981e+08  epoch time = 25.97s\n",
            "epoch =   69  loss = 7.8937e+08  epoch time = 26.06s\n",
            "epoch =   70  loss = 7.8939e+08  epoch time = 26.03s\n",
            "epoch =   71  loss = 7.8921e+08  epoch time = 25.97s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9bfa4cc68a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-9bfa4cc68a0e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_vert_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_hori_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u_vert_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u_hori_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# if batch_idx % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m#     print(f'batch: {batch_idx}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}