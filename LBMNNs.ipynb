{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PsT-57QVxLNcOleW0DCFaSRD9nonylWI",
      "authorship_tag": "ABX9TyP3JqNp6W/YmzKuA/AhyW6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/landcelita/LBMNNs/blob/master/LBMNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygrib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iltDTo-5uQCo",
        "outputId": "6920ab8b-5ccd-473d-bdf9-e82148105f9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygrib\n",
            "  Downloading pygrib-2.1.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 4.8 MB/s \n",
            "\u001b[?25hCollecting pyproj\n",
            "  Downloading pyproj-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8 MB 80.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pygrib) (1.21.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from pyproj->pygrib) (2022.12.7)\n",
            "Installing collected packages: pyproj, pygrib\n",
            "Successfully installed pygrib-2.1.4 pyproj-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Dz9u0saErhps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import time\n",
        "import datetime as dt\n",
        "import pygrib\n",
        "from datetime import timedelta\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.multiprocessing as multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHaRtnCTrsIb",
        "outputId": "c6c747e9-8078-466b-dcef-a63ed7441a73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InputLayer(nn.Module):\n",
        "    def __init__(self, height, width):\n",
        "        super().__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "    def forward(self, u_vert, u_hori, rho):\n",
        "        # use feq as input field\n",
        "        # todo: make this layer be also learnable\n",
        "        \n",
        "        # feq(x,v) = C[v] * rho * (1 + 3 v.u + 4.5 (v.u)^2 - 1.5 u^2)\n",
        "        feq = torch.empty((3, 3, self.height, self.width), dtype=torch.float32, device=device)\n",
        "        C = torch.tensor([[1.0/36.0, 1.0/9.0, 1.0/36.0], [1.0/9.0, 4.0/9.0, 1.0/9.0], [1.0/36.0, 1.0/9.0, 1.0/36.0]], dtype=torch.float32, device=device)\n",
        "        u_squared = u_vert ** 2 + u_hori ** 2\n",
        "        \n",
        "        for dr in range(-1, 2):\n",
        "            for dc in range(-1, 2):\n",
        "                v_dot_u = dr * u_vert + dc * u_hori\n",
        "                feq[dr+1, dc+1, :, :] = C[dr+1,dc+1] * rho * (1.0 + 3.0 * v_dot_u + 4.5 * v_dot_u * v_dot_u - 1.5 * u_squared)\n",
        "                \n",
        "        return feq"
      ],
      "metadata": {
        "id": "cuOiERZ-r6oB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for InputLayer\n",
        "# # Later, I'll check the immutability of the InputLayer\n",
        "#  - it must put out the same tensor even after the weights are updated\n",
        "def test_for_InputLayer():\n",
        "    input_layer_u_vert = torch.tensor([[0.1]], dtype=torch.float32, device=device)\n",
        "    input_layer_u_hori = torch.tensor([[-0.3]], dtype=torch.float32, device=device)\n",
        "    input_layer_rho = torch.tensor([[0.8]], dtype=torch.float32, device=device)\n",
        "\n",
        "    input_layer = InputLayer(1, 1).to(device)\n",
        "    feq = input_layer(input_layer_u_vert, input_layer_u_hori, input_layer_rho)\n",
        "    print(torch.sum(feq[2,:,0,0] - feq[0,:,0,0]) / torch.sum(feq[:,:,0,0])) # u_vert\n",
        "    print(torch.sum(feq[:,2,0,0] - feq[:,0,0,0]) / torch.sum(feq[:,:,0,0])) # u_hori\n",
        "    print(torch.sum(feq[:,:,0,0])) # rho\n",
        "\n",
        "test_for_InputLayer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cymZiWDGr8bd",
        "outputId": "0aaf248b-57f4-4fe3-e386-6ad1d362ad2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1000, device='cuda:0')\n",
            "tensor(-0.3000, device='cuda:0')\n",
            "tensor(0.8000, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StreamingLayer(nn.Module):\n",
        "    def __init__(self, in_height, in_width):\n",
        "        super().__init__()\n",
        "        self.in_height = in_height\n",
        "        self.in_width = in_width\n",
        "        \n",
        "        self.w0 = nn.Parameter(torch.zeros((in_height-2, in_width-2), dtype=torch.float32, device=device))\n",
        "        self.w1 = nn.Parameter(torch.ones((in_height-2, in_width-2), dtype=torch.float32, device=device))\n",
        "        \n",
        "    def forward(self, f_prev):\n",
        "        # f(x,v) = w0(x,v) + w1(x,v) * f_prev(x-v,v)\n",
        "        \n",
        "        f = torch.empty((3, 3, self.in_height-2, self.in_width-2), dtype=torch.float32, device=device)\n",
        "        for dr in range(-1, 2):\n",
        "            for dc in range(-1, 2):\n",
        "                f[dr+1,dc+1,:,:] = self.w0 + self.w1 * f_prev[dr+1,dc+1,1-dr:self.in_height-1-dr,1-dc:self.in_width-1-dc]\n",
        "        \n",
        "        return f\n",
        "                "
      ],
      "metadata": {
        "id": "j_xf25cwsBy7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for StreamingLayer\n",
        "def test_for_StreamingLayer():\n",
        "    input_f_prev = torch.zeros((3, 3, 3, 3), dtype=torch.float64, device=device)\n",
        "    input_f_prev[2,2,0,0] = 1.0\n",
        "    input_f_prev[2,1,0,1] = 2.0\n",
        "    input_f_prev[2,0,0,2] = 3.0\n",
        "    input_f_prev[1,2,1,0] = 4.0\n",
        "    input_f_prev[1,1,1,1] = 5.0\n",
        "    input_f_prev[1,0,1,2] = 6.0\n",
        "    input_f_prev[0,2,2,0] = 7.0\n",
        "    input_f_prev[0,1,2,1] = 8.0\n",
        "    input_f_prev[0,0,2,2] = 9.0\n",
        "    print(input_f_prev)\n",
        "\n",
        "    streaming_layer = StreamingLayer(3, 3).to(device)\n",
        "    f_streamed = streaming_layer(input_f_prev)\n",
        "    print(f_streamed)\n",
        "\n",
        "test_for_StreamingLayer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw9Mo_MOsFCP",
        "outputId": "0475385a-54b2-47e1-f073-5f7fa6b5d927"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 9.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 8., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [7., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 6.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 5., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [4., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 3.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[0., 2., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[1., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]]], device='cuda:0', dtype=torch.float64)\n",
            "tensor([[[[9.]],\n",
            "\n",
            "         [[8.]],\n",
            "\n",
            "         [[7.]]],\n",
            "\n",
            "\n",
            "        [[[6.]],\n",
            "\n",
            "         [[5.]],\n",
            "\n",
            "         [[4.]]],\n",
            "\n",
            "\n",
            "        [[[3.]],\n",
            "\n",
            "         [[2.]],\n",
            "\n",
            "         [[1.]]]], device='cuda:0', grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CollidingLayer(nn.Module):\n",
        "    def __init__(self, in_height, in_width):\n",
        "        super().__init__()\n",
        "        self.in_height = in_height\n",
        "        self.in_width = in_width\n",
        "        \n",
        "        self.w1 = nn.Parameter(torch.full((in_height, in_width), fill_value=3.0, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        self.w2 = nn.Parameter(torch.full((in_height, in_width), fill_value=0.0, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        self.w3 = nn.Parameter(torch.full((in_height, in_width), fill_value=4.5, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        self.w4 = nn.Parameter(torch.full((in_height, in_width), fill_value=-1.5, dtype=torch.float32, device=device), requires_grad=True)\n",
        "        \n",
        "    def forward(self, f_prev):\n",
        "        # feq(x,v) = C(v) * rho(x) * (1 + w1(x,v) v.u(x) + w2(x,v) vXu(x) + w3(x,v) (v.u(x))^2 + w4(x,v) u(x)^2)\n",
        "        # f = (f_prev + feq) / 2\n",
        "        C = torch.tensor([[1.0/36.0, 1.0/9.0, 1.0/36.0], [1.0/9.0, 4.0/9.0, 1.0/9.0], [1.0/36.0, 1.0/9.0, 1.0/36.0]], dtype=torch.float32, device=device)\n",
        "        \n",
        "        rho = torch.sum(f_prev, dim=(0,1))\n",
        "        u_vert = (f_prev[2,0,:,:] + f_prev[2,1,:,:] + f_prev[2,2,:,:] - f_prev[0,0,:,:] - f_prev[0,1,:,:] - f_prev[0,2,:,:]) / rho\n",
        "        u_hori = (f_prev[0,2,:,:] + f_prev[1,2,:,:] + f_prev[2,2,:,:] - f_prev[0,0,:,:] - f_prev[1,0,:,:] - f_prev[2,0,:,:]) / rho\n",
        "        u_squared = u_vert ** 2 + u_hori ** 2\n",
        "        feq = torch.empty((3, 3, self.in_height, self.in_width), dtype=torch.float32, device=device)\n",
        "        \n",
        "        for dr in range(-1, 2):\n",
        "            for dc in range(-1, 2):\n",
        "                v_dot_u = dr * u_vert + dc * u_hori\n",
        "                vXu = dr * u_hori - dc * u_vert\n",
        "                feq[dr+1, dc+1, :, :] = C[dr+1,dc+1] * rho * (1.0 + (self.w1 + self.w3 * v_dot_u) * v_dot_u + self.w2 * vXu + self.w4 * u_squared)\n",
        "        \n",
        "        return (f_prev + feq) / 2.0"
      ],
      "metadata": {
        "id": "p1qYEjs3sH_1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for CollidingLayer\n",
        "def test_for_CollidingLayer():\n",
        "    input_f = torch.tensor([[[[9., 9.]],[[8., 8.]],[[7., 7.]]],[[[6., 6.]],[[5., 5.]],[[4., 4.]]],[[[3., 3.]],[[2., 2.]],[[1., 1.]]]], dtype=torch.float32, device=device)\n",
        "    colliding_layer = CollidingLayer(1, 2)\n",
        "    collided_field = colliding_layer(input_f)\n",
        "\n",
        "    print(torch.sum(collided_field[:,:,0,0])) # rho 45.0\n",
        "    print((torch.sum(collided_field[2,:,0,0]) - torch.sum(collided_field[0,:,0,0])) / torch.sum(collided_field[:,:,0,0])) # u_vert\n",
        "    print((1.+2.+3.-9.-8.-7.)/45.)\n",
        "    print((torch.sum(collided_field[:,2,0,0]) - torch.sum(collided_field[:,0,0,0])) / torch.sum(collided_field[:,:,0,0])) # u_hori\n",
        "    print((1.+4.+7.-3.-6.-9.)/45.)\n",
        "\n",
        "test_for_CollidingLayer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAzNVUB0sMSw",
        "outputId": "ae35307c-bdab-4f90-96f4-330ff3f7521d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(45., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "tensor(-0.4000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "-0.4\n",
            "tensor(-0.1333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "-0.13333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputLayer(nn.Module):\n",
        "    def __init__(self, height, width):\n",
        "        super().__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "    def forward(self, f):\n",
        "        rho = torch.sum(f, dim=(0,1))\n",
        "        u_vert = (f[2,0,:,:] + f[2,1,:,:] + f[2,2,:,:] - f[0,0,:,:] - f[0,1,:,:] - f[0,2,:,:]) / rho\n",
        "        u_hori = (f[0,2,:,:] + f[1,2,:,:] + f[2,2,:,:] - f[0,0,:,:] - f[1,0,:,:] - f[2,0,:,:]) / rho\n",
        "        return u_vert, u_hori, rho"
      ],
      "metadata": {
        "id": "OD2zGC-usOZm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LBM(nn.Module):\n",
        "    margin = 4\n",
        "    \n",
        "    def __init__(self, height, width):\n",
        "        super(LBM, self).__init__()\n",
        "        self.input_layer = InputLayer(height, width)\n",
        "        self.streaming1_layer = StreamingLayer(height, width)\n",
        "        self.colliding1_layer = CollidingLayer(height-2, width-2)\n",
        "        self.streaming2_layer = StreamingLayer(height-2, width-2)\n",
        "        self.colliding2_layer = CollidingLayer(height-4, width-4)\n",
        "        self.streaming3_layer = StreamingLayer(height-4, width-4)\n",
        "        self.colliding3_layer = CollidingLayer(height-6, width-6)\n",
        "        self.streaming4_layer = StreamingLayer(height-6, width-6)\n",
        "        self.output_layer = OutputLayer(height-8, width-8)\n",
        "        \n",
        "    def forward(self, u_vert, u_hori, rho):\n",
        "        f = self.input_layer(u_vert, u_hori, rho)\n",
        "        f = self.streaming1_layer(f)\n",
        "        f = self.colliding1_layer(f)\n",
        "        f = self.streaming2_layer(f)\n",
        "        f = self.colliding2_layer(f)\n",
        "        f = self.streaming3_layer(f)\n",
        "        f = self.colliding3_layer(f)\n",
        "        f = self.streaming4_layer(f)\n",
        "        u_vert_out, u_hori_out, rho_out = self.output_layer(f)\n",
        "        return u_vert_out, u_hori_out, rho_out"
      ],
      "metadata": {
        "id": "uJllOre8sQ7Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(u_vert_pred, u_hori_pred, rho_pred, u_vert_target, u_hori_target, rho_target):\n",
        "    # MSE\n",
        "    return torch.sum(torch.square(u_vert_pred - u_vert_target) + torch.square(u_hori_pred - u_hori_target)) * 10000. +\\\n",
        "        torch.sum(torch.square(rho_pred - rho_target)) * 200."
      ],
      "metadata": {
        "id": "C4tT4O7lsTiD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherDatasetLazy(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_dir, datetimes, transform, target_transform, margin):\n",
        "        self.src_dir = src_dir\n",
        "        self.input_paths = []\n",
        "        self.target_paths = []\n",
        "        self.margin = margin # this value is the number of streaming layers that reduce the border cells.\n",
        "        # eg. ...                            xxx\n",
        "        #     ...  --(1 Streaming Layer)-->  x.x\n",
        "        #     ...                            xxx\n",
        "        for datetime in datetimes:\n",
        "            self.input_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "            datetime += timedelta(hours=3)\n",
        "            self.target_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        input_grib = pygrib.open(self.input_paths[idx])\n",
        "        rho = torch.from_numpy(np.array(input_grib.select()[0].values, dtype=np.float32)).to(device)\n",
        "        u_hori = torch.from_numpy(np.array(input_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "        u_vert = torch.from_numpy(np.array(input_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "        target_grib = pygrib.open(self.target_paths[idx])\n",
        "        rho_target = torch.from_numpy(np.array(target_grib.select()[0].values, dtype=np.float32)).to(device)\n",
        "        u_hori_target = torch.from_numpy(np.array(target_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "        u_vert_target = torch.from_numpy(np.array(target_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "        u_vert, u_hori, rho = self.transform(u_vert, u_hori, rho)\n",
        "        u_vert_target, u_hori_target, rho_target = self.target_transform(u_vert_target, u_hori_target, rho_target, self.margin)\n",
        "        return {\n",
        "            \"u_vert\": u_vert,\n",
        "            \"u_hori\": u_hori,\n",
        "            \"rho\": rho,\n",
        "            \"u_vert_target\": u_vert_target,\n",
        "            \"u_hori_target\": u_hori_target,\n",
        "            \"rho_target\": rho_target\n",
        "        }"
      ],
      "metadata": {
        "id": "6te31vRosV-1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_dir, datetimes, transform, target_transform, margin):\n",
        "        self.src_dir = src_dir\n",
        "        self.input_paths = []\n",
        "        self.target_paths = []\n",
        "        self.margin = margin # this value is the number of streaming layers that reduce the border cells.\n",
        "        # eg. ...                            xxx\n",
        "        #     ...  --(1 Streaming Layer)-->  x.x\n",
        "        #     ...                            xxx\n",
        "        for datetime in datetimes:\n",
        "            self.input_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "            datetime += timedelta(hours=3)\n",
        "            self.target_paths.append(os.path.join(src_dir, datetime.strftime('%Y%m%d%H.grib2')))\n",
        "        self.rhos = []\n",
        "        self.u_horis = []\n",
        "        self.u_verts = []\n",
        "        self.rho_targets = []\n",
        "        self.u_hori_targets = []\n",
        "        self.u_vert_targets = []\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        now = time.time()\n",
        "        for idx in range(len(self.input_paths)):\n",
        "            if (idx+1) % 100 == 0:\n",
        "                print(f'{idx+1} samples collected, {time.time() - now:.2f} s')\n",
        "                now = time.time()\n",
        "            input_grib = pygrib.open(self.input_paths[idx])\n",
        "            rho = torch.from_numpy(np.array(input_grib.select()[0].values, dtype=np.float32)).to(device)\n",
        "            u_hori = torch.from_numpy(np.array(input_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "            u_vert = torch.from_numpy(np.array(input_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "            target_grib = pygrib.open(self.target_paths[idx])\n",
        "            rho_target = torch.from_numpy(np.array(target_grib.select()[0].values, dtype=np.float32)).to(device)\n",
        "            u_hori_target = torch.from_numpy(np.array(target_grib.select()[1].values, dtype=np.float32)).to(device)\n",
        "            u_vert_target = torch.from_numpy(np.array(target_grib.select()[2].values, dtype=np.float32)).to(device)\n",
        "            self.rhos.append(rho)\n",
        "            self.u_horis.append(u_hori)\n",
        "            self.u_verts.append(u_vert)\n",
        "            self.rho_targets.append(rho_target)\n",
        "            self.u_hori_targets.append(u_hori_target)\n",
        "            self.u_vert_targets.append(u_vert_target)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        u_vert, u_hori, rho = self.transform(self.u_verts[idx], self.u_horis[idx], self.rhos[idx])\n",
        "        u_vert_target, u_hori_target, rho_target = self.target_transform(self.u_vert_targets[idx], self.u_hori_targets[idx], self.rho_targets[idx], self.margin)\n",
        "        return {\n",
        "            \"u_vert\": u_vert,\n",
        "            \"u_hori\": u_hori,\n",
        "            \"rho\": rho,\n",
        "            \"u_vert_target\": u_vert_target,\n",
        "            \"u_hori_target\": u_hori_target,\n",
        "            \"rho_target\": rho_target\n",
        "        }"
      ],
      "metadata": {
        "id": "nhjZS9lW8Ml9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(u_vert, u_hori, rho):\n",
        "    # 下向き正\n",
        "    return u_vert * -0.01, u_hori * 0.01, rho * 0.0001\n",
        "\n",
        "def target_transform(u_vert, u_hori, rho, margin):\n",
        "    if margin == 0:\n",
        "        return u_vert * -0.01, u_hori * 0.01, rho * 0.0001\n",
        "    else:\n",
        "        return u_vert[margin:-margin, margin:-margin] * -0.01, u_hori[margin:-margin, margin:-margin] * 0.01, rho[margin:-margin, margin:-margin] * 0.0001"
      ],
      "metadata": {
        "id": "R4PkTjNMscJ9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for WeatherDataset\n",
        "def test_for_weatherdataset():\n",
        "    datetimeset = [dt.datetime(2011, 7, 1), dt.datetime(2011, 7, 2)]\n",
        "    grib = pygrib.open('/content/drive/MyDrive/lab_data/data/2011070103.grib2')\n",
        "    u_vert = np.array(grib.select()[2].values, dtype=np.float32)\n",
        "    src_dir = '/content/drive/MyDrive/lab_data/data/'\n",
        "    weather_dataset = WeatherDataset(src_dir, datetimeset, transform, target_transform, 1)\n",
        "    u_vert_direct = torch.from_numpy(u_vert).to(device)\n",
        "    u_vert_target = weather_dataset.__getitem__(0)['u_vert_target']\n",
        "    print(weather_dataset.__len__()) # 2\n",
        "    print(torch.equal(u_vert_target, u_vert_direct[1:-1, 1:-1] * -0.01)) # True\n",
        "    print(u_vert_direct.size())\n",
        "\n",
        "test_for_weatherdataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0TlxIcKsev_",
        "outputId": "404937ac-0a45-4248-b66e-104797a72a48"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "True\n",
            "torch.Size([505, 481])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset_and_dataloader():\n",
        "    print('Creating a dataset and dataloader...')\n",
        "    data_dir = '/content/drive/MyDrive/lab_data/data'\n",
        "    datetimeset = [dt.datetime(2011+i, 7, 1, 0) + timedelta(days=j) for i in range(10) for j in range(92)]\n",
        "    dataset = WeatherDataset(data_dir, datetimeset, transform, target_transform, LBM.margin)\n",
        "    batch_size = 1\n",
        "    train_split = 0.8\n",
        "    shuffle_dataset = True # if false, this model will learn only by the 'past' data, and forcast the 'future' data.\n",
        "    random_seed = 42\n",
        "    \n",
        "    dataset_size =  len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(train_split * dataset_size))\n",
        "    if shuffle_dataset:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, valid_indices = indices[:split], indices[split:]\n",
        "    \n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "    \n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=0)\n",
        "    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=0)\n",
        "\n",
        "    return dataset, train_loader, valid_loader\n",
        "\n",
        "dataset, train_loader, valid_loader = make_dataset_and_dataloader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEypdBd3EN28",
        "outputId": "306d0108-50bd-4019-ce74-6a16bca16d83"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a dataset and dataloader...\n",
            "100 samples collected, 64.33 s\n",
            "200 samples collected, 65.66 s\n",
            "300 samples collected, 64.08 s\n",
            "400 samples collected, 66.79 s\n",
            "500 samples collected, 64.46 s\n",
            "600 samples collected, 64.07 s\n",
            "700 samples collected, 63.72 s\n",
            "800 samples collected, 65.35 s\n",
            "900 samples collected, 65.31 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# todo: enable the model to receive batch data\n",
        "def main(dataset, train_loader, valid_loader):\n",
        "    print('Creating the model...')\n",
        "    lbm = LBM(505, 481).to(device) # got by the prev cell\n",
        "    \n",
        "    num_epochs = 200\n",
        "    total_time = 0.0\n",
        "    \n",
        "    optimizer = torch.optim.Adam(lbm.parameters())\n",
        "    \n",
        "    print(\"optimizer = \" + str(optimizer))\n",
        "    print(\"max_epochs = %3d \" % num_epochs)\n",
        "    \n",
        "    print('Training the model...')\n",
        "    lbm.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        epoch_started_time = time.time()\n",
        "        for (batch_idx, batch) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            u_vert_out, u_hori_out, rho_out = lbm(batch['u_vert'].squeeze(), batch['u_hori'].squeeze(), batch['rho'].squeeze())\n",
        "            loss_val = loss_func(u_vert_out, u_hori_out, rho_out, batch['u_vert_target'].squeeze(), batch['u_hori_target'].squeeze(), batch['rho_target'].squeeze())\n",
        "            epoch_loss += loss_val.item()\n",
        "            loss_val.backward()\n",
        "            # if batch_idx % 100 == 0:\n",
        "            #     print(f'batch: {batch_idx}')\n",
        "            optimizer.step()\n",
        "        \n",
        "        print(\"epoch = %4d  loss = %.4e  epoch time = %0.2fs\" % (epoch, epoch_loss, time.time() - epoch_started_time))\n",
        "    print('Done')\n",
        "    \n",
        "    print('Computing the model accuracy')\n",
        "    lbm.eval()\n",
        "        \n",
        "main(dataset, train_loader, valid_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQXqhgwqsitM",
        "outputId": "4cba430d-88b5-4205-f878-1729a66e0627"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the model...\n",
            "optimizer = Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: False\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "max_epochs = 200 \n",
            "Training the model...\n",
            "epoch =    0  loss = 1.1076e+09  epoch time = 27.09s\n",
            "epoch =    1  loss = 1.0717e+09  epoch time = 26.71s\n",
            "epoch =    2  loss = 1.0596e+09  epoch time = 26.71s\n",
            "epoch =    3  loss = 1.0519e+09  epoch time = 26.69s\n",
            "epoch =    4  loss = 1.0465e+09  epoch time = 26.76s\n",
            "epoch =    5  loss = 1.0413e+09  epoch time = 26.70s\n",
            "epoch =    6  loss = 1.0377e+09  epoch time = 27.14s\n",
            "epoch =    7  loss = 1.0333e+09  epoch time = 27.37s\n",
            "epoch =    8  loss = 1.0297e+09  epoch time = 27.11s\n",
            "epoch =    9  loss = 1.0253e+09  epoch time = 27.00s\n",
            "epoch =   10  loss = 1.0229e+09  epoch time = 26.80s\n",
            "epoch =   11  loss = 1.0196e+09  epoch time = 26.78s\n",
            "epoch =   12  loss = 1.0162e+09  epoch time = 26.74s\n",
            "epoch =   13  loss = 1.0136e+09  epoch time = 26.83s\n",
            "epoch =   14  loss = 1.0116e+09  epoch time = 26.70s\n",
            "epoch =   15  loss = 1.0080e+09  epoch time = 27.17s\n",
            "epoch =   16  loss = 1.0059e+09  epoch time = 26.99s\n",
            "epoch =   17  loss = 1.0046e+09  epoch time = 27.48s\n",
            "epoch =   18  loss = 1.0017e+09  epoch time = 27.09s\n",
            "epoch =   19  loss = 9.9966e+08  epoch time = 26.82s\n",
            "epoch =   20  loss = 9.9774e+08  epoch time = 26.83s\n",
            "epoch =   21  loss = 9.9626e+08  epoch time = 26.80s\n",
            "epoch =   22  loss = 9.9372e+08  epoch time = 26.67s\n",
            "epoch =   23  loss = 9.9253e+08  epoch time = 26.71s\n",
            "epoch =   24  loss = 9.8987e+08  epoch time = 26.95s\n",
            "epoch =   25  loss = 9.8926e+08  epoch time = 27.21s\n",
            "epoch =   26  loss = 9.8740e+08  epoch time = 26.87s\n",
            "epoch =   27  loss = 9.8593e+08  epoch time = 26.83s\n",
            "epoch =   28  loss = 9.8419e+08  epoch time = 26.99s\n",
            "epoch =   29  loss = 9.8252e+08  epoch time = 27.11s\n",
            "epoch =   30  loss = 9.8161e+08  epoch time = 26.88s\n",
            "epoch =   31  loss = 9.8020e+08  epoch time = 26.69s\n",
            "epoch =   32  loss = 9.7936e+08  epoch time = 26.74s\n",
            "epoch =   33  loss = 9.7752e+08  epoch time = 26.68s\n",
            "epoch =   34  loss = 9.7657e+08  epoch time = 26.74s\n",
            "epoch =   35  loss = 9.7476e+08  epoch time = 26.73s\n",
            "epoch =   36  loss = 9.7399e+08  epoch time = 26.47s\n",
            "epoch =   37  loss = 9.7302e+08  epoch time = 27.18s\n",
            "epoch =   38  loss = 9.7176e+08  epoch time = 26.80s\n",
            "epoch =   39  loss = 9.7039e+08  epoch time = 26.45s\n",
            "epoch =   40  loss = 9.6945e+08  epoch time = 26.77s\n",
            "epoch =   41  loss = 9.6853e+08  epoch time = 27.28s\n",
            "epoch =   42  loss = 9.6728e+08  epoch time = 26.77s\n",
            "epoch =   43  loss = 9.6690e+08  epoch time = 26.67s\n",
            "epoch =   44  loss = 9.6548e+08  epoch time = 26.77s\n",
            "epoch =   45  loss = 9.6460e+08  epoch time = 26.64s\n",
            "epoch =   46  loss = 9.6306e+08  epoch time = 26.74s\n",
            "epoch =   47  loss = 9.6262e+08  epoch time = 27.03s\n",
            "epoch =   48  loss = 9.6183e+08  epoch time = 26.67s\n",
            "epoch =   49  loss = 9.6046e+08  epoch time = 26.65s\n",
            "epoch =   50  loss = 9.5994e+08  epoch time = 27.03s\n",
            "epoch =   51  loss = 9.5947e+08  epoch time = 26.59s\n",
            "epoch =   52  loss = 9.5866e+08  epoch time = 26.99s\n",
            "epoch =   53  loss = 9.5733e+08  epoch time = 26.75s\n",
            "epoch =   54  loss = 9.5682e+08  epoch time = 27.02s\n",
            "epoch =   55  loss = 9.5567e+08  epoch time = 26.76s\n",
            "epoch =   56  loss = 9.5509e+08  epoch time = 26.76s\n",
            "epoch =   57  loss = 9.5464e+08  epoch time = 26.70s\n",
            "epoch =   58  loss = 9.5412e+08  epoch time = 26.84s\n",
            "epoch =   59  loss = 9.5269e+08  epoch time = 26.60s\n",
            "epoch =   60  loss = 9.5251e+08  epoch time = 26.54s\n",
            "epoch =   61  loss = 9.5140e+08  epoch time = 26.83s\n",
            "epoch =   62  loss = 9.5065e+08  epoch time = 27.21s\n",
            "epoch =   63  loss = 9.5050e+08  epoch time = 26.78s\n",
            "epoch =   64  loss = 9.4954e+08  epoch time = 26.50s\n",
            "epoch =   65  loss = 9.4900e+08  epoch time = 27.13s\n",
            "epoch =   66  loss = 9.4858e+08  epoch time = 26.61s\n",
            "epoch =   67  loss = 9.4792e+08  epoch time = 27.03s\n",
            "epoch =   68  loss = 9.4690e+08  epoch time = 26.69s\n",
            "epoch =   69  loss = 9.4666e+08  epoch time = 26.69s\n",
            "epoch =   70  loss = 9.4629e+08  epoch time = 26.68s\n",
            "epoch =   71  loss = 9.4587e+08  epoch time = 26.88s\n",
            "epoch =   72  loss = 9.4439e+08  epoch time = 26.84s\n",
            "epoch =   73  loss = 9.4444e+08  epoch time = 26.54s\n",
            "epoch =   74  loss = 9.4402e+08  epoch time = 26.65s\n",
            "epoch =   75  loss = 9.4345e+08  epoch time = 27.15s\n",
            "epoch =   76  loss = 9.4286e+08  epoch time = 26.67s\n",
            "epoch =   77  loss = 9.4225e+08  epoch time = 26.61s\n",
            "epoch =   78  loss = 9.4171e+08  epoch time = 26.88s\n",
            "epoch =   79  loss = 9.4107e+08  epoch time = 26.66s\n",
            "epoch =   80  loss = 9.4012e+08  epoch time = 27.05s\n",
            "epoch =   81  loss = 9.3994e+08  epoch time = 26.86s\n",
            "epoch =   82  loss = 9.3954e+08  epoch time = 26.72s\n",
            "epoch =   83  loss = 9.3857e+08  epoch time = 26.75s\n",
            "epoch =   84  loss = 9.3899e+08  epoch time = 26.72s\n",
            "epoch =   85  loss = 9.3810e+08  epoch time = 26.73s\n",
            "epoch =   86  loss = 9.3821e+08  epoch time = 26.54s\n",
            "epoch =   87  loss = 9.3673e+08  epoch time = 26.95s\n",
            "epoch =   88  loss = 9.3703e+08  epoch time = 27.35s\n",
            "epoch =   89  loss = 9.3662e+08  epoch time = 26.46s\n",
            "epoch =   90  loss = 9.3610e+08  epoch time = 26.74s\n",
            "epoch =   91  loss = 9.3641e+08  epoch time = 27.13s\n",
            "epoch =   92  loss = 9.3473e+08  epoch time = 26.97s\n",
            "epoch =   93  loss = 9.3476e+08  epoch time = 26.74s\n",
            "epoch =   94  loss = 9.3467e+08  epoch time = 26.67s\n",
            "epoch =   95  loss = 9.3483e+08  epoch time = 26.69s\n",
            "epoch =   96  loss = 9.3365e+08  epoch time = 27.06s\n",
            "epoch =   97  loss = 9.3281e+08  epoch time = 26.54s\n",
            "epoch =   98  loss = 9.3288e+08  epoch time = 26.77s\n",
            "epoch =   99  loss = 9.3210e+08  epoch time = 27.09s\n",
            "epoch =  100  loss = 9.3224e+08  epoch time = 27.13s\n",
            "epoch =  101  loss = 9.3132e+08  epoch time = 26.36s\n",
            "epoch =  102  loss = 9.3148e+08  epoch time = 26.64s\n",
            "epoch =  103  loss = 9.3109e+08  epoch time = 27.06s\n",
            "epoch =  104  loss = 9.3094e+08  epoch time = 26.81s\n",
            "epoch =  105  loss = 9.3049e+08  epoch time = 26.83s\n",
            "epoch =  106  loss = 9.3005e+08  epoch time = 26.69s\n",
            "epoch =  107  loss = 9.2920e+08  epoch time = 26.72s\n",
            "epoch =  108  loss = 9.2915e+08  epoch time = 26.99s\n",
            "epoch =  109  loss = 9.2879e+08  epoch time = 26.60s\n",
            "epoch =  110  loss = 9.2852e+08  epoch time = 26.61s\n",
            "epoch =  111  loss = 9.2837e+08  epoch time = 27.41s\n",
            "epoch =  112  loss = 9.2734e+08  epoch time = 26.61s\n",
            "epoch =  113  loss = 9.2718e+08  epoch time = 26.98s\n",
            "epoch =  114  loss = 9.2726e+08  epoch time = 27.27s\n",
            "epoch =  115  loss = 9.2703e+08  epoch time = 26.73s\n",
            "epoch =  116  loss = 9.2597e+08  epoch time = 26.68s\n",
            "epoch =  117  loss = 9.2608e+08  epoch time = 26.68s\n",
            "epoch =  118  loss = 9.2549e+08  epoch time = 26.71s\n",
            "epoch =  119  loss = 9.2548e+08  epoch time = 26.77s\n",
            "epoch =  120  loss = 9.2507e+08  epoch time = 26.83s\n",
            "epoch =  121  loss = 9.2472e+08  epoch time = 26.90s\n",
            "epoch =  122  loss = 9.2477e+08  epoch time = 26.52s\n",
            "epoch =  123  loss = 9.2508e+08  epoch time = 27.12s\n",
            "epoch =  124  loss = 9.2379e+08  epoch time = 26.98s\n",
            "epoch =  125  loss = 9.2353e+08  epoch time = 26.60s\n",
            "epoch =  126  loss = 9.2379e+08  epoch time = 27.10s\n",
            "epoch =  127  loss = 9.2311e+08  epoch time = 26.97s\n",
            "epoch =  128  loss = 9.2302e+08  epoch time = 26.72s\n",
            "epoch =  129  loss = 9.2221e+08  epoch time = 26.81s\n",
            "epoch =  130  loss = 9.2275e+08  epoch time = 26.69s\n",
            "epoch =  131  loss = 9.2152e+08  epoch time = 27.12s\n",
            "epoch =  132  loss = 9.2192e+08  epoch time = 26.87s\n",
            "epoch =  133  loss = 9.2131e+08  epoch time = 26.65s\n",
            "epoch =  134  loss = 9.2092e+08  epoch time = 27.10s\n",
            "epoch =  135  loss = 9.2131e+08  epoch time = 27.19s\n",
            "epoch =  136  loss = 9.2066e+08  epoch time = 26.59s\n",
            "epoch =  137  loss = 9.2017e+08  epoch time = 26.86s\n",
            "epoch =  138  loss = 9.1968e+08  epoch time = 27.06s\n",
            "epoch =  139  loss = 9.1954e+08  epoch time = 26.88s\n",
            "epoch =  140  loss = 9.1967e+08  epoch time = 26.84s\n",
            "epoch =  141  loss = 9.1888e+08  epoch time = 26.75s\n",
            "epoch =  142  loss = 9.1892e+08  epoch time = 26.99s\n",
            "epoch =  143  loss = 9.1872e+08  epoch time = 26.62s\n",
            "epoch =  144  loss = 9.1850e+08  epoch time = 26.63s\n",
            "epoch =  145  loss = 9.1775e+08  epoch time = 27.18s\n",
            "epoch =  146  loss = 9.1819e+08  epoch time = 27.04s\n",
            "epoch =  147  loss = 9.1801e+08  epoch time = 26.83s\n",
            "epoch =  148  loss = 9.1712e+08  epoch time = 26.44s\n",
            "epoch =  149  loss = 9.1768e+08  epoch time = 26.93s\n",
            "epoch =  150  loss = 9.1689e+08  epoch time = 26.99s\n",
            "epoch =  151  loss = 9.1668e+08  epoch time = 26.81s\n",
            "epoch =  152  loss = 9.1723e+08  epoch time = 26.77s\n",
            "epoch =  153  loss = 9.1638e+08  epoch time = 27.10s\n",
            "epoch =  154  loss = 9.1604e+08  epoch time = 26.55s\n",
            "epoch =  155  loss = 9.1553e+08  epoch time = 26.78s\n",
            "epoch =  156  loss = 9.1550e+08  epoch time = 27.01s\n",
            "epoch =  157  loss = 9.1501e+08  epoch time = 27.06s\n",
            "epoch =  158  loss = 9.1588e+08  epoch time = 26.95s\n",
            "epoch =  159  loss = 9.1427e+08  epoch time = 26.66s\n",
            "epoch =  160  loss = 9.1448e+08  epoch time = 27.09s\n",
            "epoch =  161  loss = 9.1461e+08  epoch time = 26.88s\n",
            "epoch =  162  loss = 9.1389e+08  epoch time = 26.77s\n",
            "epoch =  163  loss = 9.1480e+08  epoch time = 26.79s\n",
            "epoch =  164  loss = 9.1413e+08  epoch time = 26.83s\n",
            "epoch =  165  loss = 9.1345e+08  epoch time = 26.91s\n",
            "epoch =  166  loss = 9.1430e+08  epoch time = 26.66s\n",
            "epoch =  167  loss = 9.1276e+08  epoch time = 26.91s\n",
            "epoch =  168  loss = 9.1286e+08  epoch time = 27.38s\n",
            "epoch =  169  loss = 9.1310e+08  epoch time = 26.50s\n",
            "epoch =  170  loss = 9.1226e+08  epoch time = 27.02s\n",
            "epoch =  171  loss = 9.1263e+08  epoch time = 27.14s\n",
            "epoch =  172  loss = 9.1178e+08  epoch time = 26.74s\n",
            "epoch =  173  loss = 9.1228e+08  epoch time = 26.79s\n",
            "epoch =  174  loss = 9.1137e+08  epoch time = 26.71s\n",
            "epoch =  175  loss = 9.1178e+08  epoch time = 26.69s\n",
            "epoch =  176  loss = 9.1167e+08  epoch time = 26.74s\n",
            "epoch =  177  loss = 9.1144e+08  epoch time = 26.66s\n",
            "epoch =  178  loss = 9.1067e+08  epoch time = 27.31s\n",
            "epoch =  179  loss = 9.1099e+08  epoch time = 26.72s\n",
            "epoch =  180  loss = 9.1028e+08  epoch time = 26.83s\n",
            "epoch =  181  loss = 9.1041e+08  epoch time = 27.23s\n",
            "epoch =  182  loss = 9.1008e+08  epoch time = 26.80s\n",
            "epoch =  183  loss = 9.1022e+08  epoch time = 26.77s\n",
            "epoch =  184  loss = 9.0972e+08  epoch time = 26.86s\n",
            "epoch =  185  loss = 9.0982e+08  epoch time = 26.79s\n",
            "epoch =  186  loss = 9.0935e+08  epoch time = 26.76s\n",
            "epoch =  187  loss = 9.0947e+08  epoch time = 26.94s\n",
            "epoch =  188  loss = 9.0895e+08  epoch time = 26.68s\n",
            "epoch =  189  loss = 9.0858e+08  epoch time = 27.04s\n",
            "epoch =  190  loss = 9.0841e+08  epoch time = 26.91s\n",
            "epoch =  191  loss = 9.0923e+08  epoch time = 27.07s\n",
            "epoch =  192  loss = 9.0866e+08  epoch time = 27.01s\n",
            "epoch =  193  loss = 9.0813e+08  epoch time = 26.75s\n",
            "epoch =  194  loss = 9.0712e+08  epoch time = 26.59s\n",
            "epoch =  195  loss = 9.0828e+08  epoch time = 26.66s\n",
            "epoch =  196  loss = 9.0774e+08  epoch time = 26.70s\n",
            "epoch =  197  loss = 9.0751e+08  epoch time = 26.72s\n",
            "epoch =  198  loss = 9.0676e+08  epoch time = 26.89s\n",
            "epoch =  199  loss = 9.0670e+08  epoch time = 26.55s\n",
            "Done\n",
            "Computing the model accuracy\n"
          ]
        }
      ]
    }
  ]
}